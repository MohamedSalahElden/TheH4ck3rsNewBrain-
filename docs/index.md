---
hide:
  - navigation
  - toc
---

# Resources

<div class="grid cards" markdown>

-   [![alt text](im-1.png) <br> Key Differences Between Prompt Injection and Jailbreaking](https://kenhuangus.medium.com/key-differences-between-prompt-injection-and-jailbreaking-d397cffbe812)

-   [![alt text](im-2.png) <br> Prompt Injection vs Jailbreaking: A Deeper Dive (Simon Willison)](https://simonwillison.net/2024/Mar/5/prompt-injection-jailbreaking/)

-   [![alt text](image-9.png) <br> Inject My PDF (Kai Greshake)](https://kai-greshake.de/posts/inject-my-pdf/)

-   [![alt text](im-4.png) <br> NIST AI Risk Management Framework (NIST.AI.100-2e2023)](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf)

-   [![alt text](im-5.png) <br> Understanding the RAG Architecture Model: A Deep Dive into Modern AI (Hamid Pirzada)](https://medium.com/@hamipirzada/understanding-the-rag-architecture-model-a-deep-dive-into-modern-ai-c81208afa391)

-   [ ![alt text](image-7.png)<br> How to Use Guardrails (OpenAI Cookbook)](https://cookbook.openai.com/examples/how_to_use_guardrails)

- [![alt text](image-6.png)- <br> Prompt Injection Using Emojis — Repello.ai](https://repello.ai/blog/prompt-injection-using-emojis)


- [![alt text](image-5.png) <br> Emoji Unicode — ToolExe](https://toolexe.com/text/emoji-unicode)


- [![alt text](image-8.png) <br> Emoji Jailbreaks — Google Cloud (Medium)](https://medium.com/google-cloud/emoji-jailbreaks-b3b5b295f38b)

- [![alt text](image-3.png) <br> Prompting Guide — PromptingGuide.ai](https://www.promptingguide.ai/)

- [![alt text](image-4.png) <br> Build an LLM-based Resume Analyzer — Mercity.ai](https://www.mercity.ai/blog-post/build-an-llm-based-resume-analyzer)


- [![alt text](image-2.png) <br> Prompt Injection — LearnPrompting.org](https://learnprompting.org/docs/prompt_hacking/injection?srsltid=AfmBOoolBMDC5yCC7t_1G--Bwq3bEmZzf-qmSoPmQKkpx6uCr6zZQZln)

- [![alt text](image-1.png) <br> What is a Prompt Injection Attack? — Palo Alto Networks Cyberpedia](https://www.paloaltonetworks.com/cyberpedia/what-is-a-prompt-injection-attack)


- [![alt text](image.png) <br> 20 Prompt Injection Techniques Every Red Teamer Should Test — fdzDev (Medium)](https://fdzdev.medium.com/20-prompt-injection-techniques-every-red-teamer-should-test-b22359bfd57d)


- <iframe width="900" height="300" src="https://www.youtube.com/embed/EsSQhZejsvs" title="You can Hack AI | Solve ALL Gandalf AI CTF Levels with SINGLE Prompt" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>



- <iframe width="900" height="300" src="https://www.youtube.com/embed/LfQLfmRUWuI" title="LLM01: Prompt Injection | Prompt Injection via Emojis | AI Security Expert" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>



</div>


